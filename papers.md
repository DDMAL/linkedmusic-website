---
layout: page_photo_header
title: Recent Papers
image_class: headerimage

---

<p>Dedicated to abstracts of recent papers that pertain to LinkedMusic's ideals</p>

<h2 id="2022">2022</h2>

<p>Ansovini, Daniela, Kelli Babcock, Tanis Franco, Jiyun Alex Jung, Karen Suurtamm, and Alexandra Wong. 2022. “Knowledge Lost, Knowledge Gained: The Implications of Migrating to Online Archival Descriptive Systems.” <em>KULA: Knowledge Creation, Dissemination, and Preservation Studies</em> 6 (3):1–19. https://doi.org/10.18357/kula.234.
</p>

<p>&#8226; Migrating archival description from paper-based finding aids to structured online data reconfigures the dynamics of archival representation and interactions. This paper considers the knowledge implications of transferring traditional finding aids to Discover Archives, a university-wide implementation of Access to Memory (AtoM) at the University of Toronto. The migration and translation of varied descriptive practices to conform to a single system that is accessible to anyone, anywhere, effectively shifts both where and how users interface with archives and their material. This paper reflects on how different sets of knowledge are reorganized in these shifts. The writers explore the extent to which that lost knowledge can be drawn back into archival interactions via rich metadata that documents contexts and relationships embedded within Discover Archives and beyond. Internal user experience design (UXD) research on Discover Archives highlights a gap between current online descriptions and habitual user expectations in web search and discovery. To help bridge this gap, we contributed to broader discovery nodes such as linked open "context hubs" like Wikipedia and Wikidata, which can supplement hierarchical description with linked metadata and visualization capabilities. These can reintroduce rhizomatic and serendipitous connections, enabled by archivists, researchers, and larger sets of community knowledge, to the benefit of both the user and the archivist.</p>

<p>Biswas, Russa, Yiyi Chen, Heiko Paulheim, Harald Sack, and Mehwish Alam. 2022. “It’s All in the Name: Entity Typing Using Multilingual Language Models.” In <em>Proceedings of The Semantic Web: ESWC 2022 Satellite Events</em>, 13384:59–64. Lecture Notes in Computer Science. Hersonlssos, Crete, Greece: Springer International Publishing. https://doi.org/10.1007/978-3-031-11609-4.
</p>

<p>&#8226; The entity-type information in Knowledge Graphs (KGs) of different languages plays an important role in a wide range of Natural Language Processing applications. However, the entity types in KGs are often incomplete. Multilingual entity typing is a non-trivial task if enough information is not available for the entities in a KG. In this work, multilingual neural language models are exploited to predict the type of an entity from only the name of the entity. The model has been successfully evaluated on multilingual datasets extracted from different language chapters in DBpedia namely German, French, Spanish, and Dutch.</p>

<p>Canning, Erin, Susan Brown, Sarah Roger, and Kimberley Martin. 2022. “The Power to Structure : Making Meaning from Metadata Through Ontologies.” <em>KULA: Knowledge Creation, Dissemination, and Preservation Studies, Metadata as Knowledge</em>, 6 (3):1–15. https://doi.org/10.18357/kula.169.</p>
<p>&#8226; The Linked Infrastructure for Networked Cultural Scholarship project (LINCS) helps humanities researchers tell stories by using linked open data to convert humanities datasets into organized, interconnected, machine-processable resources. LINCS provides context for online cultural materials, interlinks them, and grounds them in sources to improve web resources for research. This article describes how the LINCS team is using the shared standards of linked data and especially ontologies to bring meaning mindfully to metadata through structure. The LINCS metadata—comprised of linked open data about cultural artifacts, people, and processes—and the structures that support it must represent multiple, diverse ways of knowing. It needs to enable various means of incorporating contextual data and of telling stories with nuance and context, situated and supported by data structures that reflect and make space for specificities and complexities. As it addresses specificity in each research dataset, LINCS is simultaneously working to balance interoperability, as achieved through a level of generalization, with contextual and domain-specific requirements. The LINCS team’s approach to ontology adoption and use centers on intersectionality, multiplicity, and difference. The question of what meaning the structures being used will bring to the data is as important as what meaning is introduced as a result of linking data together, and the project has built this premise into its decision-making and implementation processes. To convey an understanding of categories and classification as contextually embedded—culturally produced, intersecting, and discursive—the LINCS team frames them not as fixed but as grounds for investigation and starting points for understanding. Metadata structures are as important as vocabularies for producing such meaning.</p>

<p>Cui, Wen, Leanne Rolston, Marilyn Walker, and Beth Ann Hockey. 2022. “OpenEL: An Annotated Corpus for Entity Linking and Discourse in Open Domain Dialogue.” In <em>Proceedings of the 13th Conference on Language Resources and Evaluation (LREC 2022)</em>, 12. Marseille, France: European Language Resources Association (ELRA). http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.241.pdf.
</p>

<p>&#8226; Entity linking in dialogue is the task of mapping entity mentions in utterances to a target knowledge base. Prior work on entity linking has mainly focused on well-written articles such as Wikipedia, annotated newswire, or domain-specific datasets. The writers extend the study of entity linking to open domain dialogue by presenting the OPENEL corpus: an annotated multi-domain corpus for linking entities in natural conversation to Wikidata. Each dialogic utterance, in 179 dialogues over 12 topics from the original EDINA corpus, has been annotated for entities realized by definite referring expressions as well as anaphoric forms such as he, she, it, and they. OPENEL thus supports training and evaluation of entity linking in open-domain dialogue, as well as analysis of the effect of using dialogue context and anaphora resolution in model training. It can also be used for fine-tuning a coreference resolution algorithm. They also establish baselines for named entity linking in open domain conversation using several existing entity linking systems.  The results demonstrate the remaining performance gap between the baselines and human performance, highlighting the challenges of entity linking in open-domain dialogue, and suggesting many avenues for future research using OPENEL.</p>

<p>Fell, Michael, Elena Cabrio, Maroua Tikat, Franck Michel, Michel Buffa, and Fabien Gandon. 2022. “The WASABI Song Corpus and Knowledge Graph for Music Lyrics Analysis.” Language Resources and Evaluation, July. https://doi.org/10.1007/s10579-022-09601-8.
</p>

<p>&#8226; The authors present the WASABI Song Corpus, a large corpus of songs enriched with meta‑data extracted from music databases on the Web, and resulting from the processing of song lyrics and from audio analysis. More specifically, given that lyrics encode an important part of the semantics of a song, the paper focuses on the description of the methods they proposed to extract relevant information from the lyrics, such as their structure segmentation, their topics, the explicitness of the lyrics content, the salient passages of a song and the emotions conveyed. The corpus contains 1.73M songs with lyrics (1.41M unique lyrics) annotated at different levels with the out‑put of the above mentioned methods. The corpus labels and the provided methods can be exploited by music search engines and music professionals (e.g. journalists, radio presenters) to better handle large collections of lyrics, allowing an intelligent browsing, categorization and recommendation of songs. They demonstrate the utility and versatility of the WASABI Song Corpus in three concrete application scenarios. Together with the work on the corpus, they present the work achieved to transition the dataset into a knowledge graph, the WASABI RDF Knowledge Graph, and show how this will enable an even richer set of applications. </p>

<p>Gayo, Jose Emilio Labra. 2022. “WShEx: A Language to Describe and Validate Wikibase Entities.” <em>ArXiv:2208.02697</em>, Computer Science, , August, 12. https://doi.org/10.48550/arXiv.2208.02697.
</p>

<p>&#8226; Wikidata is one of the most successful Semantic Web projects. Its underlying Wikibase data model departs from RDF with the inclusion of several features like qualifiers and references, built-in datatypes, etc. Those features are serialized to RDF for content negotiation, RDF dumps, and in the SPARQL endpoint. Wikidata adopted the entity schemas namespace using the ShEx language to describe and validate the RDF serialization of Wikidata entities. In this paper, the writers propose WShEx, a language inspired by ShEx that directly supports the Wikibase data model and can be used to describe and validate Wikibase entities. The paper presents the abstract syntax and semantics of the WShEx language.</p>

<p>Han, Sooyeon, and JongGyu Han. 2022. “Case Study on an Integrated Interoperable Metadata Model for Geoscience Information Resources.” <em>Geoscience Data Journal</em>, 16. https://doi.org/10.1002/gdj3.150.</p>

<p>&#8226; The article covers the creation of a metadata schema to promote interoperability and characterize historically collected geoscience data. While not in the same field, the article shows the steps taken to develop a switching-across methodology, as well as an example of the methodology. </p>

<p>Huang, Zhaoyan, and Tao Xu. 2022. “Research on Knowledge Management of Intangible Cultural Heritage Based on Linked Data.” Edited by R. Mo. Mobile Information Systems 2022 (August):1–14. https://doi.org/10.1155/2022/3384391.
</p>

<p>&#8226; At present, the protection of intangible cultural heritage has received more and more attention from all levels of society. Intangible cultural heritage is a treasure of national culture. It is an indispensable part of Chinese civilization, the crystallization of the wisdom of Chinese civilization, and represents the country’s soft power. Ontology and linked data technology provide a new method and realization path for the organization and management of intangible cultural heritage knowledge. In this paper, the intangible cultural heritage knowledge is organized reasonably semantically based on the method of linked data, and the purpose is to use the structure of linked data to express the resource data of different structures in a structured manner. This paper first introduces the meaning and background of the research and analyzes the relevant research at home and abroad. Second, it introduces the related knowledge of linked data, analyzes and sorts out the elements and semantic relationship of knowledge in the field of intangible cultural heritage, and designs and constructs the ontology model of intangible cultural heritage knowledge, Finally, based on linked data technology, the process of intangible cultural heritage knowledge organization and linked data set construction is studied, including key steps such as entity to RDF, entity association, linked data storage, and publication. The application of linked data technology in the field of intangible cultural heritage knowledge organization and management can promote the standardization and standardization of intangible cultural heritage knowledge management and is of great significance to the protection and inheritance of my country’s intangible cultural heritage culture. </p>

<p>Khan, Huda, Claire DeMarco, Christine Fernsebner Eslao, Steven Folsom, Jason Kovari, Simeon Warner, Tim Worrall, and Astrid Usong. 2022. “Using Linked Data Sources to Enhance Catalog Discovery.” <em>KULA: Knowledge Creation, Dissemination, and Preservation Studies, Metadata as Knowledge</em>, 6 (3):1–26. https://doi.org/10.18357/kula.229.</p>

<p>&#8226; This article explores how linked data sources and non-library metadata can support the open-ended discovery of library resources. They also consider which experimental methods are best suited to improving library catalog systems. They provide an overview of the questions driving our discovery experiments with linked data, a summary of their usability findings, and their design and implementation approach. In addition, they situate the discussion of their work within the larger framework of library cataloging and curation practices.</p>

<p>Lisena, Pasquale, Albert Meroño-Peñuela, and Raphaël Troncy. 2022. “MIDI2vec: Learning MIDI Embeddings for Reliable Prediction of Symbolic Music Metadata.” Edited by Mehwish Alam, Davide Buscaldi, Michael Cochez, Francesco Osborne, Diego Reforgiato Recupero, Harald Sack, Mehwish Alam, et al. <em>Semantic Web</em> 13 (3):357–77. https://doi.org/10.3233/SW-210446.</p>

<p>&#8226; An important problem in large symbolic music collections is the low availability of high-quality metadata, which is essential for various information retrieval tasks. In this work, the writers propose MIDI2vec, a new approach for representing MIDI ﬁles as vectors based on graph embedding techniques. Their strategy consists of representing the MIDI data as a graph, including the information about tempo, time signature, programs, and notes. Next, they run and optimize node2vec for generating embeddings using random walks in the graph. They demonstrate that the resulting vectors can successfully be employed for predicting the musical genre and other metadata such as the composer, the instrument, or the movement. Their proposal has real-world applications in automated metadata tagging for symbolic music, for example in digital libraries for musicology, datasets for machine learning, and knowledge graph completion.</p>

<p>Loukachevitch, Natalia, Pavel Braslavski, Vladimir Ivanov, Tatiana Batura, Suresh Manandhar, Artem Shelmanov, and Elena Tutubalina. 2022. “Entity Linking over Nested Named Entities for Russian.” In <em>Proceedings of the 13th Conference on Language Resources and Evaluation (LREC 2022)</em>, 4458–66. Marseille, France: European Language Resources Association (ELRA. http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.474.pdf.
</p>

<p>&#8226; In this paper, the writers describe entity linking annotation over nested named entities in the recently released Russian NEREL dataset for information extraction. The NEREL collection (Loukachevitch et al., 2021) is currently the largest Russian dataset annotated with entities and relations. The paper describes the main design principles behind NEREL’s entity linking annotation, provides its statistics, and reports evaluation results for several entity linking baselines. To date, 38,152 entity mentions in 933 documents are linked to Wikidata. The NEREL dataset is publicly available: https://github.com/nerel-ds/NEREL.</p>

<p>Mandal, Sukumar. 2022. “Integration of Linked Open Data Authorities with OpenRefine : A Methodology for Libraries.” <em>Library Philosophy and Practice (e-Journal)</em>, no. 7195 (May):11. https://digitalcommons.unl.edu/libphilprac/7195.
</p>

<p>&#8226; The primary purpose of this paper is to explore the integration process of linked open data authority with OpenRefine for easy access to related metadata towards the creation of data cleaning and updating in a modern integrated library system. The integration process and methods are based on the API of reconciliation repositories collected from web resources. This integrated framework will be designed and developed on OpenRefine techniques and components based on RDF, CSV, SPARQL, and Turtle scripts. This integrated framework is based on JAVA and Apache Web Server for running the OpenRefine on the Ubuntu Platform. This integrated framework has explored the data cleaning and import of bibliographic metadata from multiple linking authorities such as Open Library, ORCID, VIAF, VIAF BNF, Library of Congress Authorities data, and Wikidata. It is possible to fetch related linking authorities for enhancing the advanced level services in a modern library management system. So, library carpentry and data carpentry are essential concepts for making a dynamic integrated interface for library professionals.</p>

<p>McKenna, Lucy, Christophe Debruyne, and Declan O’Sullivan. 2022. “Using Linked Data to Create Provenance-Rich Metadata Interlinks: The Design and Evaluation of the NAISC-L Interlinking Framework for Libraries, Archives and Museums.” <em>AI & SOCIETY</em>, January, 27. https://doi.org/10.1007/s00146-021-01373-z.</p>

<p>&#8226; Linked data (LD) have the capability to open up and share materials, held in libraries, archives, and museums (LAMs), in ways that are restricted by many existing metadata standards. Specifically, LD interlinking can be used to enrich data and to improve data discoverability on the Web through interlinking related resources across datasets and institutions. However, there is currently a notable lack of interlinking across leading LD projects in LAMs, impacting the discoverability of their materials. In this article, LAM Linked Data projects and services were reviewed, including the Library of Congress, The German National Library, and the French National Library. Six Linked Data interlinking tools were also reviewed (AgreementMaker, LogMap, LinkItUp, The SILK Link Discovery Framework, The LIMES Link Discovery Framework for Metric Spaces, and the OpenRefine RDF Extension). The research also describes the Novel Authoritative Interlinking for Semantic Web Cataloguing in Libraries (NAISC-L) interlinking framework. Unlike existing interlinking frameworks, NAISC-L was designed specifically with the requirements of the LAM domain in mind. NAISC-L supports the linking of related resources across datasets and institutions, thereby enabling richer and more varied search queries, and can thus be used to improve the discoverability of materials held in LAMs.</p>

<p>Perera, Treshani. 2022. “Project Management Strategies for Managing Metadata in Institutional Recordings Collections – A Case Study.” Music Reference Services Quarterly, July, 1–22. https://doi.org/10.1080/10588167.2022.2091403.
</p>

<p>&#8226; This paper will cover project management decisions, workflows, and practical strategies adopted by a music-cataloging librarian while managing an academic institutional recordings collection. The paper is not intended to serve as a go-to resource for managing metadata in institutional recordings collections; rather, a practical approach to managing time, resources, and personnel while meeting institutional priorities as the project manager tasked with organization, metadata management, pro­ cessing, and preservation of the physical collection. The paper will cover project management strategies for creating a collection inventory, which was later expanded to a full-level metadata collection during COVID-19 remote work.</p>

<p>Proutskova, Polina, Daniel Wolff, György Fazekas, Klaus Frieler, Frank Höger, Olga Velichkina, Gabriel Solis, et al. 2022. “The Jazz Ontology: A Semantic Model and Large-Scale RDF Repositories for Jazz.” <em>Journal of Web Semantics</em> 74 (October):100735. https://doi.org/10.1016/j.websem.2022.100735.</p>

<p>&#8226; 
The Jazz Ontology is a semantic model that addresses the challenges the domain of jazz poses due to musical content and performance specificities. The model builds strongly on the Music Ontology and utilizes datasets such as MusicBrainz, the Weimar Jazz Database, and LinkedJazz to build out the Ontology further. Some elements were modified, such as creating a shortcut between the Music Ontology Performance and Signal classes, and bypassing the abstract Sound concept and Recording event. For bands, the model utilizes a relationship to connect the band to its leader and relates Performers to a single Performance to allow for musicians to change on tracks. The ontology has been assessed by examining how well it supports describing and merging existing datasets and whether it facilitates novel discoveries in a music browsing application. The utility of the ontology is also demonstrated in a novel framework for managing jazz-related music information. This involves the population of the Jazz Ontology with the metadata from large-scale audio and bibliographic corpora (the Jazz Encyclopedia and the Jazz Discography). The resulting RDF datasets were merged and linked to existing Linked Open Data resources. These datasets are publicly available and are driving an online application used by jazz researchers and music lovers for the systematic study of jazz.</p>


<p>Putnam, Nathan. 2022. “VIAF and the Linked Data Ecosystem.” <em>Jlist.It</em> 13 (1). EUM-Edizioni Università di Macerata:196–202. https://doi.org/10.4403/jlis.it-12749.</p>

<p>&#8226; This article reviews the founding, current state, and potential future of VIAF®, the Virtual International Authority File. VIAF consists of an aggregation of bibliographic and authority data from over 50 national agencies and infrastructures, systems that follow different cataloging practices, and contain hundreds of languages. After a short history of the project, the results of surveys for implementers of linked data projects on the use of VIAF data provide suggestions for future use and sustainability.</p>

<p>Tan, Mary Ann, Etienne Posthumus, and Harald Sack. 2022. “Audio Ontologies for Intangible Cultural Heritage.” In <em>Proceedings of The Semantic Web: ESWC 2022 Satellite Events</em>, 13384:171–75. Hersonlssos, Crete, Greece: Springer International Publishing. https://doi.org/10.1007/978-3-031-11609-4.
</p>

<p>&#8226; Cultural heritage portals often contain intangible objects digitized as audio files. This paper presents and discusses the adaptation of existing audio ontologies intended for non-cultural heritage applications. The resulting alignment of the German Digital Library-Europeana Data Model (DDB-EDM) with Music Ontology (MO) and Audio Commons Ontology (ACO) is presented.</p>

<p>Topham, Kate, Julian Chambliss, Justin Wigard, and Nicole Huff. 2022. “The Marmaduke Problem: A Case Study of Comics as Linked Open (Meta)Data.” <em>KULA: Knowledge Creation, Dissemination, and Preservation Studies, Metadata as Knowledge</em>, 6 (3):1–8. https://doi.org/10.18357/kula.225.</p>

<p>&#8226; Michigan State University (MSU) is home to one of the largest library comics collections in North America, holding over three hundred thousand print comic book titles and artifacts. Inspired by the interdisciplinary opportunity offered by digital humanities practice, a research collaborative linked to the MSU Library Digital Scholarship Lab (DSL) developed a Collections as Data project focused on the Comic Art Collection. This team extracted and cleaned over forty-five thousand MARC records describing comics published in Canada, Mexico, and the United States. In order to bridge digital humanities with the popular culture legacy of the institution, the MSU comics community turned to bibliographic metadata as a new way to leverage the collection for scholarly analysis. In October 2020, the Department of English Graphic Possibilities Research Workshop gathered a group of scholars, librarians, Wikidatians, and enthusiasts for a virtual Wikidata edit-a-thon. This project report will present this event as a case study to discuss how linked open metadata may be used to create knowledge and how community knowledge can, in turn, enrich metadata. They explore not only how the participants utilized the open-access tool Mix’n’match to connect the Comic Art Collection dataset to Wikidata and increase awareness of lesser-known authors and regional publishers missing from OCLC and Library of Congress databases, but how the knowledge of this community in turn revealed issues of authority control.</p>

<p>Zhang, Bohui, Filip Ilievski, and Pedro Szekely. 2022. “Enriching Wikidata with Linked Open Data.” <Em>ArXiv:2207.00143</Em>, Computer Science, , August, 17. http://arxiv.org/abs/2207.00143.
</p>

<p>&#8226; Large public knowledge graphs, like Wikidata, contain billions of statements about tens of millions of entities, thus inspiring various use cases to exploit such knowledge graphs. However, practice shows that much of the relevant information that ﬁts users’ needs is still missing in Wikidata, while current linked open data (LOD) tools are not suitable to enrich large graphs like Wikidata. In this paper, the writers investigate the potential of enriching Wikidata with structured data sources from the LOD cloud. They present a novel workﬂow that includes gap detection, source selection, schema alignment, and semantic validation. They evaluate our enrichment method with two complementary LOD sources: a noisy source with broad coverage, DBpedia, and a manually curated source with a narrow focus on the art domain, Getty. Their experiments show that our workﬂow can enrich Wikidata with millions of novel statements from external LOD sources with high quality. Property alignment and data quality are key challenges, whereas entity alignment and source selection are well-supported by existing Wikidata mechanisms. They make our code and data available to support future work. </p>


<h2 id="2021">2021</h2>

<p>Aljalahmah, Saleh H., and Oksana L. Zavalina. 2021. “Information Representation and Knowledge Organization in Cultural Heritage Institutions in Arabian Gulf: A Comparative Case Study.” <em>Journal of Information & Knowledge Management</em> 20 (4):24. https://dx.doi.org/10.1142/S0219649221500507.</p>

<p>&#8226; This paper presents the exploratory study conducted with the goal of developing an understanding of the current state of information representation and knowledge organization in cultural heritage collections in Arabian Gulf countries and perspectives for future developments. This comparative case study focused on three institutions (an archive, an academic library, and a museum), including early adopters and leaders in digital archiving in the region. The mixed-methods research combined semi-structured interviews with in-depth comparative content analysis of metadata records that represent items in institutions' collections. Despite the limitations of the small-sample analysis, this exploratory case study makes a substantial contribution to research and practice. It is the first study to evaluate information representation and knowledge organization practices in cultural heritage collections of Arabian Gulf countries. This study also can inform the planning and implementation of the large-scale study of the state and perspectives of information representation and knowledge organization across digital and physical collections of libraries, museums, and archives in the region. Suggestions for future research are included. Practical implications of the study include empirical support for the need for metadata training, development and documenting metadata creation guidelines and crosswalks, and collection and use of feedback from users and knowledge management professionals to improve information representation and knowledge organization. Results also provide insights into the interoperability potential of metadata for future regional, national, and international aggregations of cultural heritage digital collections across the Arabian Gulf region.</p>

<p>Bianchini, Carlo, Stefano Bargioni, and Camillo Carlo Pellizzari di San Girolamo. 2021. “Beyond VIAF:” <em>Information Technology and Libraries</em> 40 (2):31. https://doi.org/10.6017/ital.v40i2.12959.
</p>

<p>&#8226; This paper aims to investigate the reciprocal relationship between VIAF® and Wikidata and their possible roles in the semantic web environment. It deals with their data, their approach, their domain, and their stakeholders, with particular attention to identification as a fundamental goal of Universal Bibliographic Control. After examining interrelationships among VIAF, Wikidata, libraries, and other GLAM institutions, a double approach is used to compare VIAF and Wikidata: first, a quantitative analysis of VIAF and Wikidata data on personal entities, presented in eight tables; and second, a qualitative comparison of several general characteristics, such as purpose, scope, organizational and theoretical approach, data harvesting and management (shown in table 9). Quantitative data and qualitative comparison show that VIAF and Wikidata are quite different in their purpose, scope, organizational and theoretical approach, data harvesting, and management. The study highlights the reciprocal role of VIAF and Wikidata and their helpfulness in the worldwide bibliographical context and in the semantic web environment and outlines new perspectives for research and cooperation.</p>

<p>Boczar, Jason, Bonita Pollock, Xiying Mi, and Amanda Yeslibas. 2021. “Bridging the Gap.” <em>Information Technology and Libraries</em> 40 (4). Chicago, United States: American Library Association:1–15. https://doi.org/10.6017/ital.v40i4.13063.</p>

<p>&#8226; Due to COVID-19, many GLAM institutions saw an increase in materials going online. The University of South Florida Libraries utilized Linked Data technology to provide easy access to digital cultural heritage collections not only for the scholarly communities but also for underrepresented user groups. The paper covers the challenges of putting information online, discusses Linked Data and the solutions it can provide, and propose future work to further the effort. </p>

<p>Bonora, Paolo, and Angelo Pompilio. 2021. “Corago in LOD : The debut of an Opera repository into the Linked Data arena.” <em>Jlist.it</em>. EUM-Edizioni Università di Macerata, 54–72. https://doi.org/10.4403/jlis.it-12699.</p>

<p>&#8226; The paper examines the adoption of the Semantic Web (SW) technologies and Linked Data (LD) principles to manage a knowledge base about opera.  The Corago repository collects historical data and documentation about opera works, performances, and librettos from the 16th to the 20th  century. The writers experimented with the use of semantic technologies to manage the repository's knowledge cataloged following the Functional Requirements for Bibliographic Records (FRBR) relational model. Cultural Heritage  Knowledge Bases (CHKB) as Corago could leverage SW and LD to overcome proprietary models and to introduce new information to better satisfy users' requirements.</p>

<p>Dagher, Iman, and Denise Soufi. 2021. “Authority Control of Arabic Personal Names: RDA and Beyond.” <em>Cataloging & Classification Quarterly</em> 59 (2–3):260–80. https://doi.org/10.1080/01639374.2020.1845896.</p>

<p>&#8226; This paper discusses the basics of creating name authority records for Arabic personal names in accordance with Resource Description and Access instructions and Program for Cooperative Cataloging guidelines. A background into the use of romanization for non-Latin scripts in bibliographic and authority records is provided to establish the context. Issues with romanization that are particular to Arabic are addressed. Separate sections on modern and classical names provide an overview of the major challenges, and strategies to enhance discovery are outlined. The paper concludes with an examination of the possible benefits of identity management and other changes in the authority control landscape for names in non-Latin script.</p>

<p>Fafalios, Pavlos, Kostas Petrakis, Georgios Samaritakis, Korina Doerr, Athina Kritsotaki, Yannis Tzitzikas, and Martin Doerr. 2021. “FAST CAT: Collaborative Data Entry and Curation for Semantic Interoperability in Digital Humanities.” <em>Journal on Computing and Cultural Heritage</em> 14 (4):1–20. https://doi.org/10.1145/3461460.</p>

<p>&#8226; FAST CAT is a web-based collaborative software system for assistive data entry and curation in Digital Humanities and other forms of empirical research. The program was approached with semantic interoperability in mind, which allows for data to be exchanged with unambiguous, shared meaning. The paper details the functionality and user interface offered by FAST CAT. The paper showcases a use case via the SeaLiT project, which examines the economic, social, and demographic impacts of the introduction of steamboats in the Mediterranean area between the 1850s and the 1920s. </p>

<p>Faraj, Ghazal, and András Micsik. 2021. “Representing and Validating Cultural Heritage Knowledge Graphs in CIDOC-CRM Ontology.” <em>Future Internet</em> 13 (11). Multidisciplinary Digital Publishing Institute:277. https://doi.org/10.3390/fi13110277.</p>

<p>&#8226; In order to unify access to multiple heterogeneous sources of cultural heritage data, many datasets were mapped to the CIDOC-CRM ontology. CIDOC-CRM provides a formal structure and definitions for most cultural heritage concepts and their relationships. The COURAGE project includes historic data concerning people, organizations, cultural heritage collections, and collection items covering the period between 1950 and 1990. Therefore, CIDOC-CRM seemed the optimal choice for describing COURAGE entities, improving knowledge sharing, and facilitating the COURAGE dataset unification with other datasets. This paper introduces the results of translating the COURAGE dataset to CIDOC-CRM semantically. This mapping was implemented automatically according to predefined mapping rules. Several SPARQL queries were applied to validate the migration process manually. In addition, multiple SHACL shapes were conducted to validate the data and mapping models.</p>

<p>Filtz, Erwin, Sabrina Kirrane, and Axel Polleres. 2021. “The Linked Legal Data Landscape: Linking Legal Data across Different Countries.” <em>Artificial Intelligence and Law</em> 29 (4):485–539. https://doi.org/10.1007/s10506-021-09282-8.</p>

<p>&#8226; The European Union is working toward harmonizing legislation across Europe, in order to improve the cross-border interchange of legal information. This goal is supported for instance via standards such as the European Law Identiﬁer (ELI) and the European Case Law Identiﬁer (ECLI), which provide technical speciﬁcations for Web identiﬁers and suggestions for vocabularies to be used to describe metadata pertaining to legal documents in a machine-readable format. Notably, these ECLI and ELI metadata standards adhere to the RDF data format which forms the basis of Linked Data and therefore has the potential to form a basis for a pan-European legal Knowledge Graph. Unfortunately, to date said speciﬁcations have only been partially adopted by EU member states. In this paper, we describe a methodology to transform the existing legal information system used in Austria into such a legal knowledge graph covering different steps from modeling national speciﬁc aspects to population, and ﬁnally the integration of legal data from other countries through linked data. We demonstrate the usefulness of this approach by exemplifying practical use cases from legal information searches, which are not possible in an automated fashion so far.</p>

<p>Frosterus, Matias, David Hansson, Maral Dadvar, Ilias Kyriazis, and Sofia Zapounidou. 2021. “6 Steps for Publishing Library Linked Open Data.” LIBER Linked Open Data Working Group. https://libereurope.eu/wp-content/uploads/2021/02/LOD-Guidelines-FINAL-Feb-2021.pdf.</p>

<p>&#8226; Presented by the LIBER Linked Open Data (LOD) Working Group, this report looks at publishing LOD from a library perspective and argues why it should be employed and how. They present various aspects of the topic, introduce different options available, and lay out a foundation for possible exploration at a later stage. As such, the body of this document presents the six steps of LOD publication and explains each one of these steps in depth.</p>

<p>Gal, Avigdor, Haggai Roitman, and Roee Shraga. 2021. “Learning to Rerank Schema Matches.” <Em>IEEE Transactions on Knowledge and Data Engineering</Em> 33 (8):3104–16. https://doi.org/10.1109/TKDE.2019.2962124.</p>

<p>&#8226; Schema matching is at the heart of integrating structured and semi-structured data with applications in data warehousing, data analysis recommendations, Web table matching, etc. Schema matching is known as an uncertain process and a standard method to overcome this uncertainty introduces a human expert with a ranked list of possible schema matches to choose from, known as top-K matching. In this work, the writers propose a learning algorithm that utilizes an innovative set of features to rerank a list of schema matches and improve upon ranking the best match. They provide a bound on the size of an initial match list, tying the number of matches with the desired level of confidence in finding the best match. They also propose the use of matching predictors as features in a learning task and tailored nine new matching predictors for this purpose. The proposed algorithm assists the matching process by introducing a quality set of alternative matches to a human expert. It also serves as a step towards eliminating the involvement of human experts as decision makers in a matching process altogether. A large-scale empirical evaluation with a real-world benchmark shows the effectiveness of the proposed algorithmic solution.</p>

<p>Green, Ashlea M. 2021. “Metadata Application Profiles in U. S. Academic Libraries: A Document Analysis.” <em>Journal of Library Metadata</em> 21 (3–4). Routledge:105–43. https://doi.org/10.1080/19386389.2022.2030172.</p>

<p>&#8226; This paper describes a document analysis of 24 metadata application profiles (MAPs) used by academic libraries in the United States. The MAPs under study were collected from (a) the DLF AIG Metadata Application Profile Clearinghouse and (b) a Google search of .edu domains. Data collection and analysis took place between December 2020 and February 2021. While most of the MAPs under review provided metadata guidelines for digital collections, a small number were intended for institutional repositories or research data management. The study’s findings reveal MAP features and content, usage of controlled vocabularies and standards, and other characteristics pertaining to MAP document scope, contents, and format in this context. In addition to its discussion of the literature, the paper’s findings should help metadata specialists and others involved in digital collection management gain insights useful in the development or revision of their own metadata documentation. Further, these findings offer a current glimpse of metadata application practices among U.S. academic libraries generally.</p>

<p>Kalogeros, Eleftherios, Matthew Damigos, Michalis Sfakakis, Sofia Zapounidou, Aggeliki Drakopoulou, Costas Zervopoulos, Gerasimos Martinis, Christos Papatheodorou, and Manolis Gergatsoulis. 2021. “Digitizing, Transcribing and Publishing the Handwritten Music Score Archives of Ionian Islands Philharmonic Bands.” In <em>Metadata and Semantic Research</em>, 1537:388–99. Communications in Computer and Information Science. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-98876-0.</p>

<p>&#8226; During the long history of the philharmonic bands in the Ionian Islands, valuable archives of handwritten music scores have been established. These archives consist of the scores of original works locally created and adaptations of western music works of Greek and other European composers. For the long-term preservation of the archives of 7 Philharmonic Bands, the handwritten music scores were digitized and a significant amount of them was transcribed into MusicXML. Moreover, all these archives were integrated into and published as a single archive. All these activities were part of the project “Preservation and Prominence of the Musical Heritage of the Region of Ionian Islands Prefecture through the management of the digital archives of the Philharmonic Orchestras of the Region.” This work presents the challenges, the workflows, and the system developed to achieve the objectives of the project.</p>

<p>Kern, Christopher Julian, Thomas Schäffer, and Dirk Stelzer. 2021. “Towards Augmenting Metadata Management by Machine Learning.” <em>INFORMATIK 2021</em>, 10. https://dx.doi.org/10.18420/informatik2021-121.</p>

<p>&#8226; Managing metadata is an important section of master data management. It is a complex, comprehensive, and labor-intensive task. This paper explores whether and how metadata management can be augmented by machine learning. The writers deduce requirements for managing metadata from the literature and from expert interviews. They also identify features of machine learning algorithms. They assess 15 machine learning algorithms to determine their contribution to meeting the requirements and the extent to which they can support metadata management. Supervised and unsupervised learning algorithms, as well as neural networks, have the greatest potential to support metadata management effectively. Reinforcement learning, however, does not seem to be well suited to augment metadata management. Using Support Vector Machines and the identification of metadata as an example, we show how machine learning algorithms can support metadata management.</p>

<p>Khan, Fahad, and Ana Salgado. 2021. “Modelling Lexicographic Resources Using CIDOC-CRM, FRBRoo and Ontolex-Lemon.” In <em>Proceedings of the International Joint Workshop on Semantic Web and Ontology Design for Cultural Heritage Co-Located with the Bolzano Summer of Knowledge 2021</em>, 12. Bolzano, Italy. https://dblp.org/db/conf/swodch/swodch2021.html#KhanS21.</p>

<p>&#8226; The article describes a new approach to the modeling and publication of lexicographic resources, including retro-digitized dictionaries, as linked data. This approach is based on the use of the CIDOC-CRM aligned FRBRoo ontology together with the Ontolex-Lemon vocabulary and its follow-up lexicographic module, lexicog. After introducing the TEI-based distinction between diﬀerent views on lexicographic resources, the writers discuss Ontolex-Lemon and CIDOC-CRM, and FRBRoo. Next, they look at some motivating use cases before introducing our approach. Finally, they model one of these use cases in more depth using this approach.</p>

<p>Megdiche, Imen, Franck Ravat, and Yan Zhao. 2021. “Metadata Management on Data Processing in Data Lakes.” In <em>SOFSEM 2021: Theory and Practice of Computer Science, 12607:559–68. Lecture Notes in Computer Science</em>. Bolzano-Bozen, Italy: Springer International Publishing. https://doi.org/10.1007/978-3-030-67731-2.</p>

<p>&#8226; Data Lake (DL) is known as a Big Data analysis solution. A data lake stores not only data but also the processes that were carried out on these data. It is commonly agreed that data preparation/transformation takes most of the data analyst’s time. To improve the efficiency of data processing in a DL, the writers propose a framework that includes a metadata model and algebraic transformation operations. The metadata model ensures the findability, accessibility, interoperability, and reusability of data processes as well as data lineage of processes. Moreover, each process is described through a set of coarse-grained data trans forming operations which can be applied to different types of datasets. They illustrate and validate our proposal with a real medical use case implementation.</p>


<h2 id="2020">2020</h2>

<p>Falk, Patricia, and David R. Lewis. 2020. “A New Take on Cataloging Popular Music Recordings.” Cataloging & Classification Quarterly 58 (8):683–704. https://doi.org/10.1080/01639374.2020.1861151.</p>

<p>&#8226; Cataloging popular music audio formats such as compact discs (CDs) and LPs has always required different procedures from cataloging Western art music recordings. Bibliographic records and standards have changed during the past twenty years and catalogers have switched from using Anglo-American Cataloguing Rules (AACR2) to Resource Description and Access (RDA) for cataloging materials. This article will illustrate the changes made in popular music cataloging since the 2001 publication of Terry Simpkins’ article “Cataloging Popular Music Recordings.”Additional issues such as name authority and subject authority creation have been included, as well as new codes and Machine-readable record (MARC) tags being used in bibliographic records.</p>

<p>Koch, Ines, Cristina Ribeiro, and Carla Teixeira Lopes. 2020. “ArchOnto, a CIDOC-CRM-Based Linked Data Model for the Portuguese Archives.” In Proceedings of the Digital Libraries for Open Knowledge: 24th International Conference on Theory and Practice of Digital Libraries, 12246:149–62. Lecture Notes in Computer Science. Lyon, France: Springer International Publishing. https://doi.org/10.1007/978-3-030-54956-5.</p>

<p>&#8226; Archives are faced with great challenges due to the vast amounts of data they have to curate. New data models are required, and work is underway. The International Council on Archives is creating the RiC-CM (Records in Context), and there is a long line of work in museums with the CIDOC-CRM (CIDOC Conceptual Reference Model). Both models are based on ontologies to represent cultural heritage data and link them to other information. The Portuguese National Archives holds a collection with over 3.5 million metadata records, described with the ISAD(G) standard. The archives are designing a new linked data model and a technological platform with applications for archive contributors, archivists, and the public. The current work extends CIDOC CRM into ArchOnto, an ontology-based model for archives. The model defines the relevant archival entities and properties and will be used to migrate existing records. ArchOnto accommodates the existing ISAD(G) information and takes into account its implementation with current technologies. The model is evaluated with records from representative fonds. After the test on these samples, the model is ready to be populated with the semi-automatic transformation of the ISAD records. The evaluation of the model and the population strategies will proceed with experiments involving professional and lay users.</p>

<p>Patrício, Helena Simões, Maria Inês Cordeiro, and Pedro Nogueira Ramos. 2020. “From the Web of Bibliographic Data to the Web of Bibliographic Meaning: Structuring, Interlinking and Validating Ontologies on the Semantic Web.” International Journal of Metadata, Semantics and Ontologies 14 (2). Inderscience Publishers (IEL). https://doi.org/10.1504/IJMSO.2020.108318.</p>

<p>&#8226; Bibliographic data sets have revealed good levels of technical interoperability observing the principles and good practices of linked data. However, they have a low level of quality from the semantic point of view, due to many factors: lack of a common conceptual framework for a diversity of standards often used together, reduced number of links between the ontologies underlying data sets, the proliferation of heterogeneous vocabularies, underuse of semantic mechanisms in data structures, "ontology hijacking" (Feeney et al., 2018), point-to-point mappings, as well as limitations of semantic web languages for the requirements of bibliographic data interoperability. After reviewing such issues, a research direction is proposed to overcome the misalignments found by means of a reference model and a superontology, using Shapes Constraint Language (SHACL) to solve the current limitations of RDF languages.</p>

<p>Pegoraro Santana, Igor André, Fabio Pinhelli, Juliano Donini, Leonardo Catharin, Rafael Biazus Mangolin, Yandre Maldonado e Gomes da Costa, Valéria Delisandra Feltrim, and Marcos Aurélio Domingues. 2020. “Music4All: A New Music Database and Its Applications.” In 2020 International Conference on Systems, Signals and Image Processing (IWSSIP), 399–404. Rio de Janeiro, Brazil. https://doi.org/10.1109/IWSSIP48289.2020.9145170.</p>

<p>&#8226; One of the goals of the music information retrieval (MIR) community is to research new methods and create new systems that can efficiently and effectively retrieve and recommend songs from large databases of music content. Despite the volume of research in the area, there is a lack of music databases to support these works, i.e. databases that comply with some quite desirable requirements for the development of research, such as a huge amount of music pieces, the audio signal availability and a great diversity of audio attributes. In order to contribute to the MIR community, the authors present Music4All, a new music database that contains metadata, tags, genre information, 30-seconds audio clips, lyrics, and so on. Additionally, they also exemplify some MIR tasks that may benefit from our database and compare it with other databases proposed in the literature. </p>

<p>Pramudyo, Gani Nur, and Muhammad Rosyihan Hendrawan. 2020. “Metadata Interoperability for Institutional Repositories: A Caste Study in Malang City Academic Libraries.” In Digital Libraries at Times of Massive Societal Transition, 12504:359–67. Lecture Notes in Computer Science. Kyoto, Japan: Springer International Publishing. https://doi.org/10.1007/978-3-030-64452-9.</p>

<p>&#8226; The aim of this study is to understand, describe, and analyze metadata interoperability in Universitas Brawijaya Library which used Brawijaya Knowledge Garden (BKG) and Eprints software, University of Muhammadiyah Malang Library which used Ganesha Digital Library (GDL), and Eprints software, and Malang State Library that used Muatan Lokal (Mulok) software. This study also discussed supporting and inhibiting factors for interoperability metadata. This study employed a case study-qualitative approach. The finding indicates that metadata interoperability can be performed by using metadata crosswalks. </p>

<p>Proutskova, Polina, Anja Volk, Peyman Heidarian, and György Fazekas. 2020. “FROM MUSIC ONTOLOGY TOWARDS ETHNO-MUSIC-ONTOLOGY.” In Proceedings of 21st International Society for Music Information Retrieval Conference, 923–31. Montréal QC Canada: ISMIR Press. https://dspace.library.uu.nl/bitstream/handle/1874/414749/323.pdf?sequence=1&isAllowed=y.</p>

<p>&#8226; This paper presents exploratory work investigating the suitability of the Music Ontology [33] - the most widely used formal speciﬁcation of the music domain - for modeling non-Western musical traditions. Four contrasting case studies from a variety of musical cultures are analyzed: Dutch folk song research, the reconstructive performance of rural Russian traditions, contemporary performance and composition of Persian classical music, and recreational use of a personal world music collection. The authors propose semantic models describing the respective domains and examine the applications of the Music Ontology for these case studies: which concepts can be successfully reused, where they need adjustments, and which parts of the reality in these case studies are not covered by the Music Ontology. The variety of traditions, contexts, and modeling goals covered by the case studies sheds light on the generality of the Music Ontology and on the limits of generalization “for all musics” that could be aspired for on the Semantic Web.</p>

<p>Pugin, Laurent, and Claudio Bacciagaluppi. 2020. “An Analysis of Musical Work Datasets and Their Current Level of Linkage.” In 7th International Conference on Digital Libraries for Musicology, 32–39. Montréal QC Canada: ACM. https://doi.org/10.1145/3424911.3425518.</p>

<p>&#8226; Music works are key concepts that present a powerful linkage potential fully acknowledged in the fields of digital music libraries and digital musicology. They form an abstract connecting point for the entities referring to them, and large work datasets act as authority data that offer a promising analysis and search potential. These days, digital music libraries and digital musicology research rely primarily on datasets that have been created over the last decade, mostly from previously existing datasets, such as bibliographic records. In this paper, the authors try to provide a better understanding of the content of some of the most important datasets available and evaluate their level of linking. They analyze two leading library datasets, namely those of the Bibliothèque nationale de France (BnF) and the Deutsche Nationalbibliothek (DNB), both available in RDF format, and look at how many works they contain, how these are distributed over time, and their distribution by the composer. They compare the results with two other datasets that have completely different backgrounds, namely the Petrucci Music Library (known as IMLSP) and MusicBrainz datasets, two crowd-sourced projects. They evaluate the level of linking the two library datasets currently have with each other through the Virtual International Authority File (VIAF), and their current linking status with other libraries contributing to VIAF. They also evaluate the linking status the IMSLP and the MusicBrainz projects currently have with each other and with other datasets.</p>

<p>Thiéblin, Elodie, Ollivier Haemmerlé, Nathalie Hernandez, and Cassia Trojahn. 2020. “Survey on Complex Ontology Matching.” Edited by Marta Sabou. Semantic Web 11 (4):689–727. https://doi.org/10.3233/SW-190366.</p>

<p>&#8226; Simple ontology alignments, largely studied in the literature, link a single entity of a source ontology to a single entity of a target ontology. One of the limitations of these alignments is, however, their lack of expressiveness which can be overcome by complex alignments. While diverse state-of-the-art surveys mainly review the matching approaches in general, to the best of our knowledge, there is no study taking the speciﬁcities of the complex matching problem. In this paper, an overview of the different complex matching approaches is provided. This survey proposes a classiﬁcation of the complex matching approaches based on their speciﬁcities (i.e. type of correspondences, guiding structure). The evaluation aspects and the limitations of these approaches are also discussed. Insights for future work in the ﬁeld are provided.</p>


<hr />

